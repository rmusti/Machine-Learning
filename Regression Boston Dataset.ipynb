{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import pandas as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(boston.data ,columns=boston.feature_names )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(boston.target , columns = ['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  \n",
       "5     18.7  394.12   5.21  \n",
       "6     15.2  395.60  12.43  \n",
       "7     15.2  396.90  19.15  \n",
       "8     15.2  386.63  29.93  \n",
       "9     15.2  386.71  17.10  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD        float64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            LSTAT  \n",
      "count  506.000000  \n",
      "mean    12.653063  \n",
      "std      7.141062  \n",
      "min      1.730000  \n",
      "25%      6.950000  \n",
      "50%     11.360000  \n",
      "75%     16.955000  \n",
      "max     37.970000  \n"
     ]
    }
   ],
   "source": [
    "print(x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape: (404, 13) \n",
      "X_test shape: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "print('X_Train shape: {} \\nX_test shape: {}'  .format(x_train.shape , x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.286001</td>\n",
       "      <td>11.410891</td>\n",
       "      <td>11.008342</td>\n",
       "      <td>0.076733</td>\n",
       "      <td>0.552960</td>\n",
       "      <td>6.275651</td>\n",
       "      <td>68.318564</td>\n",
       "      <td>3.789282</td>\n",
       "      <td>9.465347</td>\n",
       "      <td>405.393564</td>\n",
       "      <td>18.483416</td>\n",
       "      <td>360.706906</td>\n",
       "      <td>12.597822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.693540</td>\n",
       "      <td>23.044664</td>\n",
       "      <td>6.858486</td>\n",
       "      <td>0.266497</td>\n",
       "      <td>0.115921</td>\n",
       "      <td>0.705096</td>\n",
       "      <td>28.099710</td>\n",
       "      <td>2.047524</td>\n",
       "      <td>8.625445</td>\n",
       "      <td>169.054034</td>\n",
       "      <td>2.111506</td>\n",
       "      <td>85.266298</td>\n",
       "      <td>7.281003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.878750</td>\n",
       "      <td>44.850000</td>\n",
       "      <td>2.109150</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>376.847500</td>\n",
       "      <td>6.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.243125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>6.214000</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>3.275900</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.955000</td>\n",
       "      <td>10.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.359358</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>93.825000</td>\n",
       "      <td>5.141475</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>16.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.534100</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.286001   11.410891   11.008342    0.076733    0.552960    6.275651   \n",
       "std      7.693540   23.044664    6.858486    0.266497    0.115921    0.705096   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082598    0.000000    5.130000    0.000000    0.449000    5.878750   \n",
       "50%      0.243125    0.000000    8.560000    0.000000    0.532000    6.214000   \n",
       "75%      3.359358   18.500000   18.100000    0.000000    0.624000    6.630000   \n",
       "max     73.534100  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    68.318564    3.789282    9.465347  405.393564   18.483416  360.706906   \n",
       "std     28.099710    2.047524    8.625445  169.054034    2.111506   85.266298   \n",
       "min      6.000000    1.129600    1.000000  188.000000   12.600000    0.320000   \n",
       "25%     44.850000    2.109150    4.000000  277.000000   17.400000  376.847500   \n",
       "50%     76.600000    3.275900    5.000000  330.000000   19.050000  391.955000   \n",
       "75%     93.825000    5.141475   24.000000  666.000000   20.200000  396.900000   \n",
       "max    100.000000   10.710300   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  404.000000  \n",
       "mean    12.597822  \n",
       "std      7.281003  \n",
       "min      1.730000  \n",
       "25%      6.867500  \n",
       "50%     10.990000  \n",
       "75%     16.605000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Regresion \n",
      "R2 Score: 0.7554467329645206 and RMSE = 23.6224589945871\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "mean_squared_error(y_test , y_pred)\n",
    "print('Using Linear Regresion \\nR2 Score: {} and RMSE = {}' .format(lr.score(x_test,y_test),mean_squared_error(y_test , y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Polynomial Feautres in Linear Regression\n",
    "poly_feautres = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_poly = poly_feautres.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_poly = poly_feautres.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape: (404, 105) \n",
      "X_test shape: (102, 105)\n"
     ]
    }
   ],
   "source": [
    "print('X_Train shape: {} \\nX_test shape: {}'  .format(x_train_poly.shape , x_test_poly.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Regresion using Polynomials \n",
      "R2 Score: 0.8395285273678416 and RMSE = 15.500634393505024\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train_poly,y_train)\n",
    "y_pred = lr.predict(x_test_poly)\n",
    "mean_squared_error(y_test , y_pred)\n",
    "print('Using Linear Regresion using Polynomials \\nR2 Score: {} and RMSE = {}' .format(lr.score(x_test_poly,y_test),mean_squared_error(y_test , y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see the imporvement in RMSE in Polynomial Features\n",
    "#Now let us see which feature has contributed the maximum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = poly_feautres.get_feature_names(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 105)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_names[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_poly_df = pd.DataFrame(x_train_poly , columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_poly_df['TARGET'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET           1.000000\n",
       "PTRATIO LSTAT    0.162177\n",
       "INDUS LSTAT      0.136845\n",
       "INDUS^2          0.122780\n",
       "CHAS DIS         0.119382\n",
       "CHAS B           0.118631\n",
       "LSTAT^2          0.103750\n",
       "TAX LSTAT        0.102840\n",
       "ZN CHAS          0.098450\n",
       "LSTAT            0.084621\n",
       "B^2              0.079898\n",
       "RAD LSTAT        0.072958\n",
       "ZN B             0.061416\n",
       "DIS RAD          0.060510\n",
       "NOX DIS          0.057173\n",
       "INDUS PTRATIO    0.052097\n",
       "INDUS AGE        0.051931\n",
       "INDUS TAX        0.051823\n",
       "DIS B            0.046468\n",
       "RM DIS           0.045873\n",
       "DIS TAX          0.043313\n",
       "NOX LSTAT        0.041304\n",
       "CRIM LSTAT       0.037755\n",
       "AGE              0.034516\n",
       "AGE PTRATIO      0.032709\n",
       "AGE LSTAT        0.031813\n",
       "PTRATIO          0.030160\n",
       "RM               0.029130\n",
       "NOX PTRATIO      0.027202\n",
       "CHAS^2           0.026775\n",
       "                   ...   \n",
       "RM TAX          -0.036855\n",
       "RM LSTAT        -0.041366\n",
       "ZN PTRATIO      -0.041540\n",
       "DIS             -0.044509\n",
       "AGE^2           -0.044951\n",
       "INDUS RAD       -0.048901\n",
       "CHAS LSTAT      -0.050487\n",
       "AGE RAD         -0.050789\n",
       "INDUS RM        -0.053032\n",
       "RM PTRATIO      -0.053045\n",
       "DIS PTRATIO     -0.055753\n",
       "RAD TAX         -0.057715\n",
       "B               -0.061195\n",
       "NOX AGE         -0.062372\n",
       "PTRATIO B       -0.065327\n",
       "AGE B           -0.065853\n",
       "INDUS B         -0.067295\n",
       "TAX B           -0.077629\n",
       "NOX B           -0.077651\n",
       "CRIM CHAS       -0.079643\n",
       "DIS LSTAT       -0.080738\n",
       "RAD B           -0.091774\n",
       "CHAS RAD        -0.094583\n",
       "CHAS AGE        -0.098908\n",
       "NOX^2           -0.101107\n",
       "INDUS CHAS      -0.101710\n",
       "B LSTAT         -0.107559\n",
       "CHAS TAX        -0.116907\n",
       "CHAS NOX        -0.136806\n",
       "1                     NaN\n",
       "Name: TARGET, Length: 106, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_poly_df.corr()['TARGET'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape: (404, 105) \n",
      "X_test shape: (102, 105)\n",
      "Using Linear Regresion using Polynomials \n",
      "R2 Score: 0.8395285273678416 and RMSE = 15.500634393505024\n"
     ]
    }
   ],
   "source": [
    "## Using Polynomial Feautres in Linear Regression\n",
    "poly_feautres = PolynomialFeatures(degree=2)\n",
    "x_train_poly = poly_feautres.fit_transform(x_train)\n",
    "x_test_poly = poly_feautres.fit_transform(x_test)\n",
    "print('X_Train shape: {} \\nX_test shape: {}'  .format(x_train_poly.shape , x_test_poly.shape))\n",
    "lr.fit(x_train_poly,y_train)\n",
    "y_pred = lr.predict(x_test_poly)\n",
    "mean_squared_error(y_test , y_pred)\n",
    "print('Using Linear Regresion using Polynomials \\nR2 Score: {} and RMSE = {}' .format(lr.score(x_test_poly,y_test),mean_squared_error(y_test , y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will do PCA on these polynomial features and and then again run the model with fewer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=52, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(x_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pca =pca.transform(x_train_poly)\n",
    "x_test_pca =pca.transform(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 52)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Regresion using Polynomials \n",
      "R2 Score: 0.8781127026002986 and RMSE = 11.773621835801388\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train_pca,y_train)\n",
    "y_pred = lr.predict(x_test_pca)\n",
    "mean_squared_error(y_test , y_pred)\n",
    "print('Using Linear Regresion using Polynomials \\nR2 Score: {} and RMSE = {}' .format(lr.score(x_test_pca,y_test),mean_squared_error(y_test , y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' So as you can see the RMSE reduced from 23(Using Linear Regression) to 17(Linear Regression + Polynomials) and then to \\n 14.6 ((Simple Regression + Polynomials + PCA)'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' So as you can see the RMSE reduced from 23(Using Linear Regression) to 17(Linear Regression + Polynomials) and then to \n",
    " 14.6 ((Simple Regression + Polynomials + PCA)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will try different with different estimators. Lasso , Ridge and ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_rgr = Lasso(alpha=1.0)\n",
    "ridge_rgr = Ridge(alpha=1.0)\n",
    "elas_rgr = ElasticNet(alpha=1 , l1_ratio= 0.5)\n",
    "\n",
    "regressors = [las_rgr , ridge_rgr ,elas_rgr]\n",
    "Lables = ['Lasso' , 'Ridge','Elastic Net']\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Lasso with  Polynomials \n",
      "R2 Score: 0.7326449557236627 and RMSE = 25.82498139146732\n",
      "Using Ridge with  Polynomials \n",
      "R2 Score: 0.8786084037464365 and RMSE = 11.72573991567757\n",
      "Using Elastic Net with  Polynomials \n",
      "R2 Score: 0.7628089033636196 and RMSE = 22.9113150770591\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for rgr , label in zip(regressors , Lables):\n",
    "    rgr.fit(x_train_pca,y_train)\n",
    "    y_pred = rgr.predict(x_test_pca)\n",
    "    rmse = mean_squared_error(y_test , y_pred)\n",
    "    print('Using {} with  Polynomials \\nR2 Score: {} and RMSE = {}' .format(label, rgr.score(x_test_pca,y_test),rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Lets now used Decision trees and Random forest'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Lets now used Decision trees and Random forest'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=100)\n",
    "randforest = RandomForestRegressor(random_state=100,n_estimators=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors += [dtree,randforest]\n",
    "Lables += ['Decision Trees' , 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Lasso with  Polynomials \n",
      "R2 Score: 0.7326449557236627 and RMSE = 25.82498139146732\n",
      "Using Ridge with  Polynomials \n",
      "R2 Score: 0.8786084037464365 and RMSE = 11.72573991567757\n",
      "Using Elastic Net with  Polynomials \n",
      "R2 Score: 0.7628089033636196 and RMSE = 22.9113150770591\n",
      "Using Decision Trees with  Polynomials \n",
      "R2 Score: 0.6946903979702188 and RMSE = 29.49117647058824\n",
      "Using Random Forest with  Polynomials \n",
      "R2 Score: 0.8250933347181875 and RMSE = 16.894992156862745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ravikanth\\K\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for rgr , label in zip(regressors , Lables):\n",
    "    rgr.fit(x_train_pca,y_train)\n",
    "    y_pred = rgr.predict(x_test_pca)\n",
    "    rmse = mean_squared_error(y_test , y_pred)\n",
    "    print('Using {} with  Polynomials \\nR2 Score: {} and RMSE = {}' .format(label, rgr.score(x_test_pca,y_test),rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Decision tree and Random forest we will not standardize the input. So lets try with non-standardize data'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''For Decision tree and Random forest we will not standardize the input. So lets try with non-standardize data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Lasso  \n",
      "R2 Score: 0.6595101798760068 and MSE = 32.88938606895188\n",
      "Using Ridge  \n",
      "R2 Score: 0.7549704577477127 and MSE = 23.668464480081393\n",
      "Using Elastic Net  \n",
      "R2 Score: 0.63194777575596 and MSE = 35.55175802991852\n",
      "Using Decision Trees  \n",
      "R2 Score: 0.6342668863261944 and MSE = 35.327745098039216\n",
      "Using Random Forest  \n",
      "R2 Score: 0.8739683769446811 and MSE = 12.173940196078432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ravikanth\\K\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for rgr , label in zip(regressors , Lables):\n",
    "    rgr.fit(x_train,y_train)\n",
    "    y_pred = rgr.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test , y_pred)\n",
    "    print('Using {}  \\nR2 Score: {} and MSE = {}' .format(label, rgr.score(x_test,y_test),rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finally we shall use Gradient Boosting techniques like XGBOOST and LGBM'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting XGBOOST\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/e7/5258cb787dc036f419ec57491decf8bfa89ab52c401b08b4b9228e43dc4c/xgboost-0.81-py2.py3-none-win_amd64.whl (7.4MB)\n",
      "Requirement already satisfied: scipy in c:\\ravikanth\\k\\lib\\site-packages (from XGBOOST) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\ravikanth\\k\\lib\\site-packages (from XGBOOST) (1.14.0)\n",
      "Installing collected packages: XGBOOST\n",
      "Successfully installed XGBOOST-0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.2, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train_pca, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test_pca, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbRegrs = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbRegrs.fit(x_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = xgbRegrs.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test , ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.142866495348967"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'reg:linear'\n",
    "    }  # the number of classes that exist in this datset\n",
    "num_round = 20 \n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test , preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.965844654973427"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' As you can see XGBOOST did not do any better than Desicion tree or Random Forest. Now lets try with LGBM'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' As you can see XGBOOST did not do any better than Desicion tree or Random Forest. Now lets try with LGBM'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting LightGBM\n",
      "  Downloading https://files.pythonhosted.org/packages/00/37/a392e669a83fef72b916009c438a924d2a9d70bc8aea62662b207105ed98/lightgbm-2.2.3-py2.py3-none-win_amd64.whl (515kB)\n",
      "Requirement already satisfied: scipy in c:\\ravikanth\\k\\lib\\site-packages (from LightGBM) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\ravikanth\\k\\lib\\site-packages (from LightGBM) (0.19.1)\n",
      "Requirement already satisfied: numpy in c:\\ravikanth\\k\\lib\\site-packages (from LightGBM) (1.14.0)\n",
      "Installing collected packages: LightGBM\n",
      "Successfully installed LightGBM-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.2, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmRegr = lgbm.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ravikanth\\K\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lgbmRegr.fit(x_train_poly , y_train)\n",
    "y_pred = lgbmRegr.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.243990383340249"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
